{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9N2NBlsadu1"
      },
      "outputs": [],
      "source": [
        "data_path = 'D:/workspace/gpt/gptdata/melon_ballad.csv'\n",
        "model_save = 'D:/workspace/gpt/gptdata/8.ë°œë¼ë“œê°€ì‚¬.csv'\n",
        "output_path = 'result/ë°œë¼ë“œê°€ì‚¬'\n",
        "input =  'ì œì£¼ ì• ì›”ì í•´ë³€ìœ„ì— ì•‰ì•„ ì‚¬ì§„ì„ ì°ëŠ”ë‹¤.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwaFDTbaadu4"
      },
      "source": [
        "# ì „ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRo3mixFadu5"
      },
      "outputs": [],
      "source": [
        "def cleasing(text):\n",
        "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mailì£¼ì†Œì œê±°\n",
        "    text = re.sub(pattern=pattern, repl='', string=text)\n",
        "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URLì œê±°\n",
        "    text = re.sub(pattern=pattern, repl='', string=text)\n",
        "    pattern = '([ã„±-ã…ã…-ã…£]+)' # í•œê¸€ ììŒ, ëª¨ìŒ ì œê±°\n",
        "    text = re.sub(pattern=pattern, repl='', string=text)\n",
        "    pattern = '<[^>]*>'         # HTML íƒœê·¸ ì œê±°\n",
        "    text = re.sub(pattern=pattern, repl='', string=text)\n",
        "    text = re.sub(pattern='\\n[0-9]', repl='', string=text)\n",
        "    # pattern = '[^\\w\\s]' # íŠ¹ìˆ˜ê¸°í˜¸ì œê±°\n",
        "    # text = re.sub(pattern=pattern, repl='', string=text)\n",
        "    return text    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpXY-E-kadu6",
        "outputId": "a9d6f8e6-9b75-4453-da27-95354e9c3d85"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ìš¸ê³  ìˆëŠ” ê·¸ ì—¬ì˜ ì•„ë‚˜ìš”ê·¸ëŒˆ ê¸°ë‹¤ë¦¬ëŠ” ë°”ë³´ ê°™ì€ ì‚¬ëŒë©€ì–´ì ¸ ê°„ë‹¨ ê±¸ ì•Œë©´ì„œë„ê·¸ëŒˆ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ê·¸ ì–¸ì  ê°€ ë³„ë¹›ì— ìƒˆê¸´ ì¶”ì–µ í•˜ë‚˜ê°€ë°”ëŒì— ë‘ê³  ì˜¨ ë„ˆì˜ ì´ë¦„ì„ ë¶ˆëŸ¬ì™€ë„ˆì˜ ì´ë¦„ì€ ë– ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ì–¸ì œì˜€ì£  ê·¸ëŒ€ ë‚´ê²Œ ì²˜ìŒ ì˜¤ë˜ ë‚ ì•„ì§ë„ ë‚œ ì„¤ë ˆëŠ”ê±¸ìš”ëˆˆì´ ë¶€ì‹œë˜ ê·¸ëŒ€ ëª¨ìŠµë‚´ ë§˜ í”...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ì–´ë””ê¹Œì§€ ë§ì„ í• ê¹Œì–´ë–¡í•˜ë©´ ë§˜ì„ ì•Œê¹Œê¸°ë‹¤ë¦´ ìˆ˜ë„ ë” ë²„í‹¸ ìˆ˜ë„ ì—†ëŠ”ë¬´ì‹¬íˆ ë‚˜ë¥¼ ë³´ë„¤...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ì–¸ì  ê°€ëŠ” ê·¸ëŒ€ë¥¼ ìŠì„ ë•Œë„ ì˜¤ê² ì§€ì˜¤ëœ ì‹œê°„ ì§€ë‚˜ë©´ì• ì¨ ê·¸ëŒˆ ì§€ìš°ë ¤ í•˜ì§€ëŠ” ì•Šì•„ë„ ë˜...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>ì˜¤ëŠ˜ì¼ì¤„ì•¼ ëŠ˜ìƒê°ì€ í–ˆì§€ë§Œì´ë¥¸ê±°ì•„ëƒ ì¢€ì„œìš´í•˜ë‹¤ë„¤ê°€ í–ˆë˜ ë”°ëœ»í•œ ë§ì˜ ì˜¨ë„ì—¬ê¸° ê·¸ëŒ€ë¡ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>ì§‘ìœ¼ë¡œ ê°€ëŠ” ë°¤ê¸¸ê¿ˆë„ ì ì´ ë“  ì´ ë°¤ê°€ë¡œë“± ë¹› ì•„ë˜ê³µí—ˆí•˜ê²Œ ë‚ ì•„ë“œëŠ” í•˜ë£¨ì‚´ì´ëª¸ì„ ëˆ„...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>ë‚´ì¼ì´ ë˜ë©´ë„ ì‚¬ë‘í•˜ê²Œ ë  ê±°ì•¼ì˜ˆì •ëœ ì¼ì¸ ê±¸ë¶ˆì•ˆí•œ í™”ìŒë“¤ê³¼ë¶€ë”ªëŠ” í˜„ì˜ ë–¨ë¦¼ì ì  ì„ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>You called me your loverYou called me your fri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>í•˜ì–€ê½ƒ ë‚´ë¦¬ëŠ” ìƒˆë²½ê¸¸ ëª¨í‰ì´ì–´ë‘ìš´ ëˆˆê¸¸ì— ì–¸ì† ë¹„ë¹„ë©°ì°¨ê°€ìš´ ì‹ ë¬¸ì§€ ëˆë¬¶ì–´ ê°ì•„ì¥ê³ ë‹¬...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              contents\n",
              "0    ìš¸ê³  ìˆëŠ” ê·¸ ì—¬ì˜ ì•„ë‚˜ìš”ê·¸ëŒˆ ê¸°ë‹¤ë¦¬ëŠ” ë°”ë³´ ê°™ì€ ì‚¬ëŒë©€ì–´ì ¸ ê°„ë‹¨ ê±¸ ì•Œë©´ì„œë„ê·¸ëŒˆ ...\n",
              "1    ê·¸ ì–¸ì  ê°€ ë³„ë¹›ì— ìƒˆê¸´ ì¶”ì–µ í•˜ë‚˜ê°€ë°”ëŒì— ë‘ê³  ì˜¨ ë„ˆì˜ ì´ë¦„ì„ ë¶ˆëŸ¬ì™€ë„ˆì˜ ì´ë¦„ì€ ë– ...\n",
              "2    ì–¸ì œì˜€ì£  ê·¸ëŒ€ ë‚´ê²Œ ì²˜ìŒ ì˜¤ë˜ ë‚ ì•„ì§ë„ ë‚œ ì„¤ë ˆëŠ”ê±¸ìš”ëˆˆì´ ë¶€ì‹œë˜ ê·¸ëŒ€ ëª¨ìŠµë‚´ ë§˜ í”...\n",
              "3    ì–´ë””ê¹Œì§€ ë§ì„ í• ê¹Œì–´ë–¡í•˜ë©´ ë§˜ì„ ì•Œê¹Œê¸°ë‹¤ë¦´ ìˆ˜ë„ ë” ë²„í‹¸ ìˆ˜ë„ ì—†ëŠ”ë¬´ì‹¬íˆ ë‚˜ë¥¼ ë³´ë„¤...\n",
              "4    ì–¸ì  ê°€ëŠ” ê·¸ëŒ€ë¥¼ ìŠì„ ë•Œë„ ì˜¤ê² ì§€ì˜¤ëœ ì‹œê°„ ì§€ë‚˜ë©´ì• ì¨ ê·¸ëŒˆ ì§€ìš°ë ¤ í•˜ì§€ëŠ” ì•Šì•„ë„ ë˜...\n",
              "..                                                 ...\n",
              "995  ì˜¤ëŠ˜ì¼ì¤„ì•¼ ëŠ˜ìƒê°ì€ í–ˆì§€ë§Œì´ë¥¸ê±°ì•„ëƒ ì¢€ì„œìš´í•˜ë‹¤ë„¤ê°€ í–ˆë˜ ë”°ëœ»í•œ ë§ì˜ ì˜¨ë„ì—¬ê¸° ê·¸ëŒ€ë¡ ...\n",
              "996  ì§‘ìœ¼ë¡œ ê°€ëŠ” ë°¤ê¸¸ê¿ˆë„ ì ì´ ë“  ì´ ë°¤ê°€ë¡œë“± ë¹› ì•„ë˜ê³µí—ˆí•˜ê²Œ ë‚ ì•„ë“œëŠ” í•˜ë£¨ì‚´ì´ëª¸ì„ ëˆ„...\n",
              "997  ë‚´ì¼ì´ ë˜ë©´ë„ ì‚¬ë‘í•˜ê²Œ ë  ê±°ì•¼ì˜ˆì •ëœ ì¼ì¸ ê±¸ë¶ˆì•ˆí•œ í™”ìŒë“¤ê³¼ë¶€ë”ªëŠ” í˜„ì˜ ë–¨ë¦¼ì ì  ì„ ...\n",
              "998  You called me your loverYou called me your fri...\n",
              "999  í•˜ì–€ê½ƒ ë‚´ë¦¬ëŠ” ìƒˆë²½ê¸¸ ëª¨í‰ì´ì–´ë‘ìš´ ëˆˆê¸¸ì— ì–¸ì† ë¹„ë¹„ë©°ì°¨ê°€ìš´ ì‹ ë¬¸ì§€ ëˆë¬¶ì–´ ê°ì•„ì¥ê³ ë‹¬...\n",
              "\n",
              "[1000 rows x 1 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "df = pd.read_csv(data_path)\n",
        "df.columns = ['contents']\n",
        "df = df[['contents']]\n",
        "df[\"contents\"] = df[\"contents\"].str.replace(pat=r'[^a-zA-Z0-9ã„±-ã…£ê°€-í£. ]', repl=r'', regex=True)\n",
        "df[\"contents\"] = df[\"contents\"].str.replace(pat=r'[\\n]', repl=r'', regex=True)\n",
        "df_new = []\n",
        "tmp = df['contents']\n",
        "for i in range(len(tmp)):\n",
        "    tmp2 = str(tmp[i]).split('.  ')\n",
        "    tmp2 = list(filter(None, tmp2))\n",
        "    tmp2 = [item + '.' for item in tmp2]\n",
        "    df_new.extend(tmp2)\n",
        "df_new = pd.DataFrame(df_new, columns=['contents'])\n",
        "df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IYZdGmaadu7",
        "outputId": "d656ae00-8148-479b-e5fa-40e1d16bb089"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 20888.59it/s]\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "for i in tqdm.tqdm(range(len(df_new))):\n",
        "    df_new['contents'][i] = cleasing(df_new['contents'][i])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PW4yAvAadu7"
      },
      "outputs": [],
      "source": [
        "df_new.to_csv(model_save)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTIQWhvvadu8"
      },
      "source": [
        "# ëª¨ë¸ë§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPSvUgTT4aWH"
      },
      "outputs": [],
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "def load_dataset(file_path, tokenizer, block_size = 128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer = tokenizer,\n",
        "        file_path = file_path,\n",
        "        block_size = block_size,\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "def load_data_collator(tokenizer, mlm = False):\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer = tokenizer,\n",
        "        mlm = mlm,\n",
        "    )\n",
        "    return data_collator\n",
        "\n",
        "def train(train_file_path, model_name, output_dir, overwrite_output_dir,\n",
        "          per_device_train_batch_size, num_train_epochs, save_steps):\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name,\n",
        "                bos_token = '</s>', eos_token = '</s>', unk_token = '<unk>',\n",
        "                pad_token = '<pad>', mask_token = '<mask>')\n",
        "    train_dataset = load_dataset(train_file_path, tokenizer)\n",
        "    data_collator = load_data_collator(tokenizer)\n",
        "\n",
        "    tokenizer.save_pretrained(output_dir, legacy_format = False)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    model.save_pretrained(output_dir)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir = output_dir,\n",
        "        overwrite_output_dir = overwrite_output_dir,\n",
        "        per_device_eval_batch_size = per_device_train_batch_size,\n",
        "        num_train_epochs = num_train_epochs,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model = model,\n",
        "        args = training_args,\n",
        "        data_collator = data_collator,\n",
        "        train_dataset = train_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvpLKULL5BGH"
      },
      "outputs": [],
      "source": [
        "model_name = 'skt/kogpt2-base-v2'\n",
        "output_dir = output_path\n",
        "overwrite_output_dir = False\n",
        "per_device_train_batch_size = 8\n",
        "num_train_epochs = 5.0\n",
        "save_steps = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbe7YigHadu-",
        "outputId": "afa020e9-ebf3-4673-8c78-09ee46b25ec0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.69M/2.69M [00:01<00:00, 2.12MB/s]\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 0.98k/0.98k [00:00<00:00, 995kB/s]\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
            "C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 490M/490M [00:06<00:00, 85.1MB/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1749\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1095\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 500/1095 [00:54<01:00,  9.84it/s]Saving model checkpoint to result/ë°œë¼ë“œê°€ì‚¬\\checkpoint-500\n",
            "Configuration saved in result/ë°œë¼ë“œê°€ì‚¬\\checkpoint-500\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.5264, 'learning_rate': 2.71689497716895e-05, 'epoch': 2.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in result/ë°œë¼ë“œê°€ì‚¬\\checkpoint-500\\pytorch_model.bin\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1000/1095 [01:49<00:09,  9.82it/s]Saving model checkpoint to result/ë°œë¼ë“œê°€ì‚¬\\checkpoint-1000\n",
            "Configuration saved in result/ë°œë¼ë“œê°€ì‚¬\\checkpoint-1000\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.5968, 'learning_rate': 4.337899543378996e-06, 'epoch': 4.57}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in result/ë°œë¼ë“œê°€ì‚¬\\checkpoint-1000\\pytorch_model.bin\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1094/1095 [02:03<00:00,  9.84it/s]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1095/1095 [02:04<00:00,  8.82it/s]\n",
            "Saving model checkpoint to result/ë°œë¼ë“œê°€ì‚¬\n",
            "Configuration saved in result/ë°œë¼ë“œê°€ì‚¬\\config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 124.3228, 'train_samples_per_second': 70.341, 'train_steps_per_second': 8.808, 'train_loss': 2.9972877397929154, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "train_file_path = model_save\n",
        "train(train_file_path,\n",
        "    model_name = model_name,\n",
        "    output_dir = output_dir,\n",
        "    overwrite_output_dir = overwrite_output_dir,\n",
        "    per_device_train_batch_size = per_device_train_batch_size,\n",
        "    num_train_epochs = num_train_epochs,\n",
        "    save_steps = save_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LvSkmCk5REU"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "\n",
        "def load_model(model_path):\n",
        "  model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "  return model\n",
        "\n",
        "def load_tokenizer(tokenizer_path):\n",
        "  tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n",
        "  return tokenizer\n",
        "\n",
        "def generate_text(sequence, max_lenth):\n",
        "  model_path =output_path\n",
        "  model = load_model(model_path)\n",
        "  tokenizer = load_tokenizer(model_path)\n",
        "  ids = tokenizer.encode(f'{sequence},', return_tensors = 'pt')\n",
        "  final_outputs = model.generate(\n",
        "      ids,\n",
        "      do_sample = True,\n",
        "      max_length = max_length,\n",
        "      pad_token_id = model.config.pad_token_id,\n",
        "      repetition_penalty = 1.5, # ë‹¨ì–´ ë¹ˆë„ íŒ¨ë„í‹°\n",
        "      no_repeat_ngram_size=2, # ë°˜ë³µ ì¤„ì´ê¸° nê°œ ì´ìƒì˜ í† í°ì´ ë°˜ë³µë  ê²½ìš° ë“±ì¥í™•ë¥ ì„ 0ìœ¼ë¡œ ë§Œë“¬\n",
        "      temperature=0.9, # ëª¨ë¸ì˜ ë‹¤ìŒ í† í° í™•ë¥ ë¶„í¬ì— ë³€í˜•ì„ ì¤˜ ë¬¸ì¥ì„ ë‹¤ì–‘í•˜ê²Œ ìƒì„±\n",
        "      tok_k = 50, # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ì§€ë‹Œ nê°œì˜ ë‹¨ì–´ìˆ˜ ì¤‘ ì¶”ì¶œ\n",
        "      top_p = 0.9 # ëˆ„ì í™•ë¥ ì´ n%ì¸ ë‹¨ì–´ê¹Œì§€ í¬í•¨í•˜ì—¬ ì¶”ì¶œ\n",
        "  )\n",
        "  result = tokenizer.decode(final_outputs[0], skip_special_tokens = True)\n",
        "  result = re.sub(pattern='\\n[0-9][0-9][0-9][0-9],', repl='', string=result)\n",
        "  result = re.sub(pattern='\\n[0-9][0-9][0-9],', repl='', string=result)\n",
        "  result = re.sub(pattern='  ', repl=' ', string=result)\n",
        "  result = re.sub(pattern=',', repl=' ', string=result)\n",
        "  result = re.sub(pattern='  ', repl=' ', string=result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJK5mZ3C5Veg",
        "outputId": "9df4a9a6-3995-45ca-9d83-d1b7e856c9ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input :ì œì£¼ ì• ì›”ì í•´ë³€ìœ„ì— ì•‰ì•„ ì‚¬ì§„ì„ ì°ì—ˆë‹¤.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'ì œì£¼ ì• ì›”ì í•´ë³€ìœ„ì— ì•‰ì•„ ì‚¬ì§„ì„ ì°ì—ˆë‹¤. Dont have to goAnd I swear appearing downWhenever you know we hady forgetìš°ë¦¬ê°€ ë§ˆì£¼í•œ ì´ ìˆœê°„ë“¤ì´ì–´ëŠìƒˆ ë¹›ë‚˜ë²„ë ¸ì£  ê·¸ëŒ„ ì„¬ì²˜ëŸ¼ ë”°ëœ»í•´ìš”Yeah Were makes not alrightê·¸ëŒ€ëŠ” í–‰ë³µí•©ë‹ˆë‹¤ë§Œ ìš°ë¦¬ê°€ ì–´ë–»ê²Œ ìš°ë¦°ì˜ì›í•  ìˆ˜ ìˆìŠµë‹ˆê¹Œ.7ì›”ì˜ ì–´ëŠë‚ ë¬¸ë“ ë„¤ ìƒê°ì´ ë‚¬ì—ˆì§€ë‚´ê°€ ìˆëŠ” ê³³ ì—¬ê¸° ë„ˆê°€ ìˆì–´ë§¤ì¼ê°™ì´ ë‚ ì•„ë‹¤ë‹ˆëŠ” ìˆ˜ë§ì€ ë°¤'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input = 'ì œì£¼ ì• ì›”ì í•´ë³€ìœ„ì— ì•‰ì•„ ì‚¬ì§„ì„ ì°ì—ˆë‹¤.'\n",
        "sequence = input\n",
        "max_length = 128 \n",
        "print('input :' + sequence)\n",
        "result = generate_text(sequence, max_length)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiX8t-NEtvcs",
        "outputId": "773eb9ca-87ec-4078-a9d8-215d2b5242dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n",
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n",
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n",
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n",
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Dont have to goAnd I swear appearing downWhenever you know we hady forgetìš°ë¦¬ê°€ ë§ˆì£¼í•œ ì´ ìˆœê°„ë“¤ì´ì–´ëŠìƒˆ ë¹›ë‚˜ë²„ë ¸ì£  ê·¸ëŒ„ ì„¬ì²˜ëŸ¼ ë”°ëœ»í•´ìš”Yeah Were makes not alrightê·¸ëŒ€ëŠ” í–‰ë³µí•©ë‹ˆë‹¤ë§Œ ìš°ë¦¬ê°€ ì–´ë–»ê²Œ ìš°ë¦°ì˜ì›í•  ìˆ˜ ìˆìŠµë‹ˆê¹Œ.',\n",
              " 'ce of loveEven thats into please tell but debtforryHoldings c.',\n",
              " 'Theres not say youI want to haveMy hand and I knowYour everydrast momentBeautizen the darkAnd fineWere gonna learching foreverspecial onCaused without changelisperish from airSo HighThe view at anciistD.',\n",
              " 'bluebreakthings insideL.',\n",
              " 'Im still highThe past is come darkness the worldHere my lifeAnd I special everyday you and i kill findYeah that apart of nightBut gonna tell our ratherWas only foreverEven just stop reachingMemories tooAfterJust alive AwardNobody Originality attempto.']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_result = []\n",
        "for _ in range(5):\n",
        "    tmp1 = result.strip(input)\n",
        "    tmp1 = tmp1.strip(', ')\n",
        "    tmp1 = tmp1.strip(',. ')\n",
        "    tmp2 = tmp1.split('.')\n",
        "    input = tmp2[0]+'.'\n",
        "    input = input.replace('\\n', '')\n",
        "    max_length = 128 \n",
        "    output_result.append(input)\n",
        "    globals()['result'] = generate_text(input, max_length)\n",
        "output_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkz3MMAnadvA",
        "outputId": "4dce613b-4e37-4faa-bf25-dc7cf618bfb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input :ì œì£¼ ì• ì›”ì í•´ë³€ìœ„ì— ì•‰ì•„ ì‚¬ì§„ì„ ì°ì—ˆë‹¤. í–‰ë³µí•¨.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'ì œì£¼ ì• ì›”ì í•´ë³€ìœ„ì— ì•‰ì•„ ì‚¬ì§„ì„ ì°ì—ˆë‹¤. í–‰ë³µí•¨. ìˆ˜ë§ì€ ì‚¬ì§„ ì†ì— ë¹„ì¹œ ë‚˜ì˜ ë§˜ê·¸ëŒ€ ëª¨ìŠµ ë³´ì—¬ì¤˜ì„œë¯¸ì†Œë¥¼ ì§€ì–´ë„ ìŠì§€ ë§ì•„ ì¤¬ìœ¼ë©´ í•´.ì˜¤ëœë§Œì´ì•¼ ìš°ë¦° ìŠì–´ê°”ë˜ ìš°ë¦¬ì„œë¡œê°€ ì„œë¡œë¥¼ ì•Œì§€ ëª»í–ˆë˜ë§ˆìŒì˜ ìƒì²˜ê°€ ì´ì œ ë„ˆë¬´ ê¹Šì–´ì§„ ê²ƒ ê°™ì•„ë‚˜ í˜¼ì ë‚¨ê²¨ì§„ ì‹œê°„ë“¤ë‹¤ í˜ë ¤ë³´ë‚¸ ê²ƒë“¤ì´ë‚´ê²Œë§Œ ë‚¨ì•„ ë” ë¯¸ì› ê³ ë„ˆì™€ í•¨ê»˜í•œ ì¶”ì–µì´ ë‹¤ ì–´ë””ë¡œ ì‚¬ë¼ì¡ŒëŠ”ì§€í˜¼ì ë‚¨ì€ ê¸°ì–µë“¤ë¡œí•˜ë£¨ í•˜ë£¨ ì§€ë‚˜ë³´ë‚´ì§€ë„ ëª»í•œ ë‚˜ì˜€ì§€ê·¸ë˜ ë„ˆ ì—†ì´ ì‚´ì•„ê°ˆ ìˆ˜ ì—†ì–´ìš°ë¦¬ê°€ ì„œë¡œ ëª¨ë¥¼ ë¦¬ ì—†ì§€ë‹ˆê°€ ë– ë‚œ ë’¤ì—” ë‚´ ì‚¬ë‘ë“¤ë„ ì „ë¶€'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input = 'ì œì£¼ ì• ì›”ì í•´ë³€ìœ„ì— ì•‰ì•„ ì‚¬ì§„ì„ ì°ì—ˆë‹¤. í–‰ë³µí•¨.'\n",
        "sequence = input\n",
        "max_length = 128 \n",
        "print('input :' + sequence)\n",
        "result = generate_text(sequence, max_length).strip(r'[^a-zA-Z0-9ã„±-ã…£ê°€-í£. ]')\n",
        "result = re.sub(pattern='\\n[0-9][0-9][0-9][0-9],', repl='', string=result)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDBZfE3radvA",
        "outputId": "360e04a2-4f7e-420e-85e0-9ad5a9778c56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n",
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n",
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n",
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n",
            "loading configuration file result/ë°œë¼ë“œê°€ì‚¬\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file result/ë°œë¼ë“œê°€ì‚¬\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at result/ë°œë¼ë“œê°€ì‚¬.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file result/ë°œë¼ë“œê°€ì‚¬\\added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\special_tokens_map.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer_config.json\n",
            "loading file result/ë°œë¼ë“œê°€ì‚¬\\tokenizer.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['ìˆ˜ë§ì€ ì‚¬ì§„ ì†ì— ë¹„ì¹œ ë‚˜ì˜ ë§˜ê·¸ëŒ€ ëª¨ìŠµ ë³´ì—¬ì¤˜ì„œë¯¸ì†Œë¥¼ ì§€ì–´ë„ ìŠì§€ ë§ì•„ ì¤¬ìœ¼ë©´ í•´.',\n",
              " '118 7ì›”ì˜ ì–´ëŠë‚  ìš°ì—°íˆë„¤ê²Œ ì „í™”ë¥¼ ê±¸ì—ˆëŠ”ë°ì†ì‚­ì¸ë‹¤ì´ì   ì•ˆë…• ì „í™”ê¸° ë„ˆë¨¸ë¡œ ë“¤ë ¤ì˜¤ëŠ”ë„ˆì˜ ëª©ì†Œë¦¬ëŠ”ì•„ì§ë„ ë‚´ ê·“ê°€ì— ìƒìƒí•´ë„ˆì™€ í•¨ê»˜í–ˆë˜ ê·¸ë•Œì— ë‚œì–´ë‘  ì†ì„ í—¤ë§¤ê³  ìˆì–´ì˜¤ëŠ˜ ë°¤ë§Œ ê¸°ë‹¤ë ¤ì™”ëŠ”ë°ì´ëŒ€ë¡œ ì ë“¤ë©´ ì–´ë–¨ê¹Œë‚´ì¼ ì•„ì¹¨ì— ë˜ ì—°ë½ì˜¬êº¼ì•¼ì™œ ì´ëŸ°ì§€ ëª°ë¼ë‹µí•œ ë§ˆìŒì— ê³„ì† ë„¤ ì—°ë½ì„ ê¸°ë‹¤ë¦¬ê³¤ í–ˆëŠ”ì§€ë˜ë‹¤ì‹œ ìƒê°ì´ ë‚˜ì„œê³„ì† ìƒê°í•´ë³´ë‹ˆë‚´ê°€ ì´ëŸ´ìˆ˜ê°€ ìˆë‚˜ ë´ëë‚˜ì§€ ì•ŠëŠ” ê¸´ë°¤.',\n",
              " 'ì£¼ì¹˜ì§€ ì•Šê¸°ë¥¼ê·¸ëŒ€ì˜ ì†ê¸¸ë„ ì•„ì§ì€ ì„œíˆ´ë €ë˜ ê²ƒ ê°™ì•„ë¯¸ì•ˆí•˜ë‹¤ëŠ” ë§.',\n",
              " 'ì´ ë°¤ ë‚œ ë„ˆì˜ ê³ì„ ë– ë‚˜ë³´ë„¤.',\n",
              " 'ê·¸ ë§ˆìŒì²˜ëŸ¼ëª¨ë“  ê²Œ ê¿ˆë§Œ ê°™ì•„ì¢‹ì•˜ë˜ ì‹œê°„ë“¤ì´ ë‹¤ì‹œ ëŒì•„ì™€ê·¸ë• ì°¸ ì¢‹ì•˜ì—ˆëŠ”ë°ì–´ë””ë¥¼ ë‘˜ëŸ¬ë´ë„ ë‚˜ í˜¼ìë§Œì˜ ì°©ê° ì†ì—ì˜¤ëŠ˜ë”°ë¼ ë” ë³´ê³  ì‹¶ì–´ë„ˆì™€ ê±·ê³  ì‹¶ì€ ê·¸ëŸ° ë‚˜ë¼ì„œë„¤ê²Œ ê¸°ëŒ€ ì–´ì  ë°¤ìƒˆ ëˆˆë¬¼ì´ í˜ëŸ¬ëì´ ì—†ë‹¤ëŠ” ê±¸ ì•Œì•„ì•„ì‰¬ì›€ì— ë¹ ì ¸ ë˜ í•˜ë£¨ë¥¼ ë³´ë‚´ì•¼ í•´ë‚´ì¼ì´ë©´ ë‹¤ ëë‚˜ê² ì§€ëŠ¦ì€ ì¶œë°œì´ë¼ í›„íšŒí•  ê±°ì•¼ë‚˜ì—ê²Œë„ ë¯¸ë ¨ìœ¼ë¡œ ë‚¨ê¸¸ ë°”ë˜ìŠìœ¼ë ¤ê³  ì• ì¨ ë³¼ìˆ˜ë¡ë” ì•„ì‰¬ì›Œì§€ëŠ” ë„ ë³´ë©°í˜¼ì ëˆˆë¬¼ì§“ë˜ ë‚˜ë¥¼ë‹¤ì‹œëŠ” ì¡ì§€ ë§ìê³ í•˜ë£¨.']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_result = []\n",
        "for i in range(5):\n",
        "    tmp1 = result.strip(input)\n",
        "    tmp1 = tmp1.strip(',')\n",
        "    tmp1 = tmp1.strip(', ')\n",
        "    tmp1 = tmp1.strip(',. ')\n",
        "    tmp2 = tmp1.split('.')\n",
        "    input = tmp2[0]+'.'\n",
        "    input = input.replace('\\n', '')\n",
        "    max_length = 128 \n",
        "    output_result.append(input)\n",
        "    globals()['result'] = generate_text(input, max_length)\n",
        "output_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0_bRMphadvA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "KoGPT2á„†á…©ë¸_ë°œë¼ë“œê°€ì‚¬.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
