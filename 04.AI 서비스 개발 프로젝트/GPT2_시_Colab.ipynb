{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_Ïãú_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b3ab6ceef24a4b849ea3012824a27991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_348bda1eb0984b29a8bd0f3e29bfb5ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_201e1a8758bb44adb51dc1a548d38d6b",
              "IPY_MODEL_780ce19f746247bca0afe85e61eddf1a",
              "IPY_MODEL_3b428e7fc8bc4648b2081cc3d584e7d9"
            ]
          }
        },
        "348bda1eb0984b29a8bd0f3e29bfb5ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "201e1a8758bb44adb51dc1a548d38d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fbc84f7a166e497391694facddc04b15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19f091342e9f4cd2b4d4c3de36bda466"
          }
        },
        "780ce19f746247bca0afe85e61eddf1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5aff97a1b6c4b29848b06047773cf15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2825034,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2825034,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_731be3f363444886a2ba40bedaf05435"
          }
        },
        "3b428e7fc8bc4648b2081cc3d584e7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93da1955f9e0427a9ed389df52e9449e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.69M/2.69M [00:00&lt;00:00, 15.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_527b891fd645440494faf83bdd4245d1"
          }
        },
        "fbc84f7a166e497391694facddc04b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19f091342e9f4cd2b4d4c3de36bda466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5aff97a1b6c4b29848b06047773cf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "731be3f363444886a2ba40bedaf05435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93da1955f9e0427a9ed389df52e9449e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "527b891fd645440494faf83bdd4245d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "783db691156542e19e087137df8b9836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b7b5f6a25efe4abcb339adb52964f168",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b6a102048f346e1ba574fe344293630",
              "IPY_MODEL_679fb80518014cc29176a9f7f7cff10c",
              "IPY_MODEL_115fde283bb24668b4ce3225922cb6d9"
            ]
          }
        },
        "b7b5f6a25efe4abcb339adb52964f168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b6a102048f346e1ba574fe344293630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_24c431c2e79b49e4b79a53a67669f338",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26402a06852a49f3aff62398730df734"
          }
        },
        "679fb80518014cc29176a9f7f7cff10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f4043249ae364893a423b700b606f79f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_482ced23d8c349c6a30a8976daed4d25"
          }
        },
        "115fde283bb24668b4ce3225922cb6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2a8ed780a6f4fb0b7d0360273c751a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.98k/0.98k [00:00&lt;00:00, 36.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15f27126b5e142deaacedac05ba15838"
          }
        },
        "24c431c2e79b49e4b79a53a67669f338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26402a06852a49f3aff62398730df734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4043249ae364893a423b700b606f79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "482ced23d8c349c6a30a8976daed4d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2a8ed780a6f4fb0b7d0360273c751a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15f27126b5e142deaacedac05ba15838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd5cd5563fb740c99995a83f346d902e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1135243213994c9db368c3484a7f8db2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b30d0cc19f8c47a1a83f75ab5958eb63",
              "IPY_MODEL_abc120f66c4c42aaa9645ef07be7b8de",
              "IPY_MODEL_160440b3c89f4411a02b5ad5e5bd5673"
            ]
          }
        },
        "1135243213994c9db368c3484a7f8db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b30d0cc19f8c47a1a83f75ab5958eb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_809ceb3a0d8f41118e82d3f0ebbe3605",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6602b7f2caa940c896dc045be6518c32"
          }
        },
        "abc120f66c4c42aaa9645ef07be7b8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0356bd003f2847c8a09c3eb316f46d2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 513302779,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 513302779,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ef82a0832ce45439808a810b43f176b"
          }
        },
        "160440b3c89f4411a02b5ad5e5bd5673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e188843c79a4848afdc1ef0827e6f72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 490M/490M [00:13&lt;00:00, 38.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75ce64d97aa04ffcbd6930e34879b171"
          }
        },
        "809ceb3a0d8f41118e82d3f0ebbe3605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6602b7f2caa940c896dc045be6518c32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0356bd003f2847c8a09c3eb316f46d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ef82a0832ce45439808a810b43f176b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e188843c79a4848afdc1ef0827e6f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75ce64d97aa04ffcbd6930e34879b171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79tPay9jj-ez",
        "outputId": "6eafc319-74bf-4b34-c114-e58826c4aa45"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQl0JdY7mb1l",
        "outputId": "f17c877a-8efd-42fe-d36b-6653a51878c4"
      },
      "source": [
        "cd /content/drive/MyDrive/data/project03/gpt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/project03/gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87efFg6ptmuS"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTqH3xB-whPh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOmOc5w6maKS"
      },
      "source": [
        "# ÌõàÎ†®Î™®Îç∏\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "def load_dataset(file_path, tokenizer, block_size = 128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer = tokenizer,\n",
        "        file_path = file_path,\n",
        "        block_size = block_size,\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "def load_data_collator(tokenizer, mlm = False):\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer = tokenizer,\n",
        "        mlm = mlm,\n",
        "    )\n",
        "    return data_collator\n",
        "\n",
        "def train(train_file_path, model_name, output_dir, overwrite_output_dir,\n",
        "          per_device_train_batch_size, num_train_epochs, save_steps):\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name,\n",
        "                bos_token = '</s>', eos_token = '</s>', unk_token = '<unk>',\n",
        "                pad_token = '<pad>', mask_token = '<mask>')\n",
        "    train_dataset = load_dataset(train_file_path, tokenizer)\n",
        "    data_collator = load_data_collator(tokenizer)\n",
        "\n",
        "    tokenizer.save_pretrained(output_dir, legacy_format = False)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    model.save_pretrained(output_dir)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir = output_dir,\n",
        "        overwrite_output_dir = overwrite_output_dir,\n",
        "        per_device_eval_batch_size = per_device_train_batch_size,\n",
        "        num_train_epochs = num_train_epochs,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model = model,\n",
        "        args = training_args,\n",
        "        data_collator = data_collator,\n",
        "        train_dataset = train_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model()\n",
        "\n",
        "# Ïã§Ìñâ Î™®Îç∏\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "\n",
        "def load_model(model_path):\n",
        "  model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "  return model\n",
        "\n",
        "def load_tokenizer(tokenizer_path):\n",
        "  tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n",
        "  return tokenizer\n",
        "\n",
        "def generate_text(sequence, max_lenth):\n",
        "  model_path = '/content/drive/MyDrive/data/project03/gpt/results'\n",
        "  model = load_model(model_path)\n",
        "  tokenizer = load_tokenizer(model_path)\n",
        "  ids = tokenizer.encode(f'{sequence},', return_tensors = 'pt')\n",
        "  final_outputs = model.generate(\n",
        "      ids,\n",
        "      do_sample = True,\n",
        "      max_length = max_length,\n",
        "      pad_token_id = model.config.pad_token_id,\n",
        "      tok_k = 30, # Í∞ÄÏû• ÎÜíÏùÄ ÌôïÎ•†ÏùÑ ÏßÄÎãå nÍ∞úÏùò Îã®Ïñ¥Ïàò Ï§ë Ï∂îÏ∂ú\n",
        "      top_p = 0.95 # ÎàÑÏ†ÅÌôïÎ•†Ïù¥ n%Ïù∏ Îã®Ïñ¥ÍπåÏßÄ Ìè¨Ìï®ÌïòÏó¨ Ï∂îÏ∂ú\n",
        "      # repetition_penalty = 10 # Îã®Ïñ¥ ÎπàÎèÑ Ìå®ÎÑêÌã∞\n",
        "  )\n",
        "  result = tokenizer.decode(final_outputs[0], skip_special_tokens = True)\n",
        "  return result"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "b3ab6ceef24a4b849ea3012824a27991",
            "348bda1eb0984b29a8bd0f3e29bfb5ae",
            "201e1a8758bb44adb51dc1a548d38d6b",
            "780ce19f746247bca0afe85e61eddf1a",
            "3b428e7fc8bc4648b2081cc3d584e7d9",
            "fbc84f7a166e497391694facddc04b15",
            "19f091342e9f4cd2b4d4c3de36bda466",
            "e5aff97a1b6c4b29848b06047773cf15",
            "731be3f363444886a2ba40bedaf05435",
            "93da1955f9e0427a9ed389df52e9449e",
            "527b891fd645440494faf83bdd4245d1",
            "783db691156542e19e087137df8b9836",
            "b7b5f6a25efe4abcb339adb52964f168",
            "2b6a102048f346e1ba574fe344293630",
            "679fb80518014cc29176a9f7f7cff10c",
            "115fde283bb24668b4ce3225922cb6d9",
            "24c431c2e79b49e4b79a53a67669f338",
            "26402a06852a49f3aff62398730df734",
            "f4043249ae364893a423b700b606f79f",
            "482ced23d8c349c6a30a8976daed4d25",
            "d2a8ed780a6f4fb0b7d0360273c751a2",
            "15f27126b5e142deaacedac05ba15838",
            "dd5cd5563fb740c99995a83f346d902e",
            "1135243213994c9db368c3484a7f8db2",
            "b30d0cc19f8c47a1a83f75ab5958eb63",
            "abc120f66c4c42aaa9645ef07be7b8de",
            "160440b3c89f4411a02b5ad5e5bd5673",
            "809ceb3a0d8f41118e82d3f0ebbe3605",
            "6602b7f2caa940c896dc045be6518c32",
            "0356bd003f2847c8a09c3eb316f46d2f",
            "6ef82a0832ce45439808a810b43f176b",
            "0e188843c79a4848afdc1ef0827e6f72",
            "75ce64d97aa04ffcbd6930e34879b171"
          ]
        },
        "id": "WvwbuLsYwihG",
        "outputId": "76869036-2f88-4115-be9e-9eb18a2d67ed"
      },
      "source": [
        "# ÌõàÎ†®\n",
        "# ÌõàÎ†® ÌååÏùº Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
        "train_file_path = '/content/drive/MyDrive/data/project03/gpt/music/melon_rap_lyrics.csv'\n",
        "model_name = 'skt/kogpt2-base-v2'\n",
        "output_dir = '/content/drive/MyDrive/data/project03/gpt/results'\n",
        "overwrite_output_dir = False\n",
        "per_device_train_batch_size = 8\n",
        "num_train_epochs = 1.5\n",
        "save_steps = 500\n",
        "\n",
        "train(train_file_path = train_file_path,\n",
        "      model_name = model_name,\n",
        "      output_dir = output_dir,\n",
        "      overwrite_output_dir = overwrite_output_dir,\n",
        "      per_device_train_batch_size = per_device_train_batch_size,\n",
        "      num_train_epochs = num_train_epochs,\n",
        "      save_steps = save_steps\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3ab6ceef24a4b849ea3012824a27991",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.69M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "783db691156542e19e087137df8b9836",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd5cd5563fb740c99995a83f346d902e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/490M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1968\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 369\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='216' max='369' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [216/369 06:58 < 04:58, 0.51 it/s, Epoch 0.87/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwC7iJr3xLMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde973c3-e541-4822-f0ee-382f7d3ac223"
      },
      "source": [
        "# Ïã§Ìñâ\n",
        "# ÏÖãÌåÖ tok_k = 50, top_p = 0.95\n",
        "input = 'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ'\n",
        "sequence = input\n",
        "max_length = 128 \n",
        "print('input :' + sequence)\n",
        "generate_text(sequence, max_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/data/project03/gpt/results/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/data/project03/gpt/results/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input :ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/data/project03/gpt/results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/data/project03/gpt/results/added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer_config.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ, ÎÑâÎÑâÌïú Ïó¨Î¶Ñ  \n",
            "ÌïòÎäòÏù¥ ÎÜíÏûê ÎÇòÎπÑÎäî ÍΩÉÏ≤òÎüº ÌïòÎäò ÌíàÏóê ÏïàÎäêÎùº ÎÇ†ÏúºÎäî Îë• ÎßàÎäî Îë•  ÌïòÎäòÏùÄ Ïò®ÌÜµ ÌïòÏñÄÏÉâ  ÎÇòÎπÑÎäî ÍΩÉÏ≤òÎüº ÌïòÎäò ÌíàÏóê ÏïàÎäêÎùº ÎÇ†ÏúºÎäî Îë•  \n",
            "\"Î∞îÎûåÏù¥ ÎßéÎã§.  Î∂ÄÎäî Î∞îÎûåÏù¥ ÎÑàÎ¨¥ ÌÅ¨Îã§.  Ïò§Îäî ÎπÑÎèÑ Í≥†Ïö∏ ÎøêÏù¥Îã§.  ÍΩÉÎèÑ ÎßéÍ≥† ÎÇòÎ¨¥ÎèÑ ÎßéÍ≥† ÍΩÉÎÇòÎ¨¥ÎèÑ ÎßéÎã§.  Ï†Ä ÌÉúÏö∏ Í≤É ÏóÜÎã§.  \"\n",
            "\"Ïù¥Î∂à Ìïú ÎçÆÏù¥Ïóê ÎàÑÏö¥ ÏÜêÎ™©Ïù¥ Î∞òÏßùÏù¥Îã§.  ÏÜåÎÇòÍ∏∞Ïóê ÎπÑÎ•º Î™®ÏïÑ ÎçÆÏóàÎçò Í≤É Í∞ôÏïÑ  Í∑∏ ÏÜêÎÅùÏùÄ Ï¢ÖÏùº Í≥†Í∞§ Ï†ÅÏ§ëÌñàÎã§.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNPq8lhXHJVi",
        "outputId": "7ca88591-ac4a-40f1-bcc1-1f64e5fc822e"
      },
      "source": [
        "# Ïã§Ìñâ\n",
        "# tok_k = 1, top_p = 0.9, repetition_penalty = 1.5 \n",
        "input = 'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ'\n",
        "sequence = input\n",
        "max_length = 128 \n",
        "# print('input :' + sequence)\n",
        "sentence = generate_text(sequence, max_length)\n",
        "sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/data/project03/gpt/results/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/data/project03/gpt/results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/data/project03/gpt/results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/data/project03/gpt/results/added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer_config.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ, ÎÑâÎÑâÌïú Ïó¨Î¶Ñ  \n",
            "ÌïòÎäòÏù¥ ÎÜíÏûê ÎÇòÎπÑÎäî ÍΩÉÏ≤òÎüº ÌïòÎäò Ìñ•Ìï¥ ÎÇ†Í≥† ÏÉàÍ∞Ä ÌïòÎäòÏùÑ Ìñ•ÌïúÎã§Îçò ÏÇ¨ÎûåÏù¥ ÏûàÏóàÏñ¥. Í≥†ÏïΩÌïú Î∞îÎûåÏùÄ Ïó¨ÏßÅ Ìë∏Î•∏ ÎÇòÎ•º Î∂ôÎì§ÏóàÎã§. Í∞ÄÏãú ÎèãÏπú ÎìØ ÌôúÏßùÏùÄ Îã¨ ÏïÑÎûò Î≤åÎ≤å Î∂ÄÎäî Î∞îÎûå Í∑∏Ï≥êÎùº. Í∞ÄÏùÑÏù¥Îùº ÎçîÏö± Îß§ÏÑ≠Í≤åÎßå ÌîºÍ≤†Îã§.  ÎÑàÎäî Ïù¥Ï†úÍªè Ìïú ÏÜ°Ïù¥ÎèÑ ÏóÜÎäî Í≤ÉÏùÑ Ï†Ä ÌòºÏûê Îçî ÎßéÏù¥ Î≥¥ÏïòÍµ¨ÎÇò, Ïã∂ÎÑ§.‚Äô\n",
            "\"Î∞îÎã§Îäî Ï¢ÅÏäµÎãàÎã§. Î∞îÎûåÏù¥ ÎÑàÎ¨¥ ÏÑ∏ÏÑú Í±∑Í∏∞ÎèÑ ÎßêÎ¶¨Í∏∞Í∞Ä Ï¢Ä ÏßÄÏπòÏã† Í≤É Í∞ôÏïÑÏöî. ÎÇ¥ÏùºÏùÄ Íº≠ ÎπÑÏºúÎã§Ïò§ ÌïòÍ≥† ÏïΩÏÜç ÏûàÏñ¥Ïöî, Îòê ÎÜìÏúºÏÜåÏÑú ÌïòÏãúÎ©¥ Î®∏ÏßÄÏïä\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGE6vIOLJKm4",
        "outputId": "fbcab560-eda5-4e3c-9caf-d502bfa70bb2"
      },
      "source": [
        "# Ïã§Ìñâ\n",
        "# tok_k = 10, top_p = 0.9, repetition_penalty = 1.5 \n",
        "input = 'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ'\n",
        "sequence = input\n",
        "max_length = 128 \n",
        "# print('input :' + sequence)\n",
        "sentence = generate_text(sequence, max_length)\n",
        "sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/data/project03/gpt/results/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/data/project03/gpt/results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/data/project03/gpt/results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/data/project03/gpt/results/added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer_config.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ, ÎãπÏã† ÏóÜÏúºÎ©¥ Íº≠  ÎÇòÎßå Î≥¥Í≥† Ïã∂Ïñ¥.)\n",
            "ÌïòÎäòÏù¥ ÏÉàÎ°ú ÏñªÏùÄ ÌïòÎäò, Ïù¥ ÎßàÏùåÎåÄÎ°úÏù∏ Í≤ÉÎèÑ ÏïÑÎãàÍ≥† Îã¨ÎèÑ ÏÉà Î≥ÑÏù¥ÎùºÎãà ÎÇòÎèÑ Ïñ¥Ï≤òÍµ¨ÎãàÏóÜÏñ¥. ÎùºÎ©∞ ÎÇ¥ÎØºÎã§. ÎùºÏù¥ÌÑ∞Í∞Ä Ï†úÎ≤ï ÏûòÏÉùÍ≤ºÍ≥† Î∂àÍ∑∏Î†àÎ†à Ï≤≠Î™ÖÌïú Í∞ÄÏùÑ ÌïòÎäòÏù¥ ÎßàÏùåÏóê ÏïàÎì†Îã§Îäî ÎßêÏùÑ Îì§ÏóàÎã§. ÎùºÎ©¥ Ìïú Í∑∏Î¶áÏù¥Îçò Í≤ÉÏù¥ Îëê ÏªµÏúºÎ°ú Ï§ÑÎçîÎãà ÏÑ∏ Ï§ÑÎ°úÎÇòÏÑú Î∞±ÏπòÎûë Ìà¨Îã•Ìà¨Îã• Î∂ôÎäîÎã§Í≥† ÌñàÎã§. Ï†ÄÎßàÎã§Ïùò Î≤ÑÎ¶áÏóê ÎßûÍ≤å Ï¢ãÏùÄ Îç∞Î•º Í≥®Îùº Î®πÎèÑÎ°ù ÌïòÏãúÏò§.\"\n",
            "\"Ïó¨ÏßÅ ÎÑ§ ÎßàÏùåÏù¥Ïïº ÎÇ®ÏïÑ ÏïÑÏâ¨Ïö∏ Í≤É ÏóÜÏúºÎãà Îã§ÌñâÏù¥Îã§. Í∑∏ÎûòÎèÑ ÎÑàÍ∑∏Îü¨Ïõå\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxDkVAgsK96x",
        "outputId": "e24f675e-a46d-49fa-9bc1-a07f83d96250"
      },
      "source": [
        "# Ïã§Ìñâ\n",
        "# tok_k = 50, top_p = 0.9, repetition_penalty = 1.5 \n",
        "input = 'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ'\n",
        "sequence = input\n",
        "max_length = 128 \n",
        "# print('input :' + sequence)\n",
        "sentence = generate_text(sequence, max_length)\n",
        "sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/data/project03/gpt/results/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/data/project03/gpt/results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/data/project03/gpt/results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/data/project03/gpt/results/added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer_config.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ, ÎÑâÎÑâÌïú Ïó¨Î¶Ñ  \n",
            "ÌïòÎäòÏù¥ ÎÜíÏûê ÎÇòÎπÑÎäî ÍΩÉÏ≤òÎüº ÌïòÎäò Ìñ•Ìï¥ ÎÇ†Í≥† ÏÉàÍ∞Ä ÌïòÎäòÏùÑ Ìñ•ÌïúÎã§Îçò ÏÇ¨ÎûåÏù¥ ÏûàÏóàÏñ¥. Í≥†ÏïΩÌïú Î∞îÎûåÏùÄ Ïó¨ÏßÅ Ìë∏Î•∏ ÎÇòÎ•º Î∂ôÎì§ÏóàÎã§. Í∞ÄÏãú ÎèãÏπú ÎìØ ÌôúÏßùÏùÄ Îã¨ ÏïÑÎûò Î≤åÎ≤å Î∂ÄÎäî Î∞îÎûå Í∑∏Ï≥êÎùº. Í∞ÄÏùÑÏù¥Îùº ÎçîÏö± Îß§ÏÑ≠Í≤åÎßå ÌîºÍ≤†Îã§.  ÎÑàÎäî Ïù¥Ï†úÍªè Ìïú ÏÜ°Ïù¥ÎèÑ ÏóÜÎäî Í≤ÉÏùÑ Ï†Ä ÌòºÏûê Îçî ÎßéÏù¥ Î≥¥ÏïòÍµ¨ÎÇò, Ïã∂ÎÑ§.‚Äô\n",
            "\"Î∞îÎã§Îäî Ï¢ÅÏäµÎãàÎã§. Î∞îÎûåÏù¥ ÎÑàÎ¨¥ ÏÑ∏ÏÑú Í±∑Í∏∞ÎèÑ ÎßêÎ¶¨Í∏∞Í∞Ä Ï¢Ä ÏßÄÏπòÏã† Í≤É Í∞ôÏïÑÏöî. ÎÇ¥ÏùºÏùÄ Íº≠ ÎπÑÏºúÎã§Ïò§ ÌïòÍ≥† ÏïΩÏÜç ÏûàÏñ¥Ïöî, Îòê ÎÜìÏúºÏÜåÏÑú ÌïòÏãúÎ©¥ Î®∏ÏßÄÏïä\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kxNq1S42GnTH",
        "outputId": "e27cb7e7-dad9-48d3-cd91-8aaa08dc9146"
      },
      "source": [
        "# Ïã§Ìñâ\n",
        "# tok_k = 50, top_p = 0.9, repetition_penalty = 1 \n",
        "input = 'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ'\n",
        "sequence = input\n",
        "max_length = 256\n",
        "# print('input :' + sequence)\n",
        "sentence = generate_text(sequence, max_length)\n",
        "sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/data/project03/gpt/results/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/data/project03/gpt/results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/data/project03/gpt/results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/data/project03/gpt/results/added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer_config.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ  \"\\n\"ÎπóÏÜç Îã§ ÏßÄÎÇò Í∞ëÎãàÎã§.  ÎçîÎäî ÎπóÎ¨ºÏÜåÎ¶¨ Îì£ÏßÄ Îßê Í±∏.  Ïó¨ÏßÅÎèÑ Ï†ñÏùÄ Î™∏ ÎÖπÏùº Í≥≥ Î™ªÌïòÎÑ§.  \"\\n\"Ïó¨Î¶ÑÏùÄ Ï†êÏ†ê Ïó¨Î¶ÑÎåÄÎ°úÎ•º Í±∑Í≥† Í∞ÄÏùÑÏùÄ Í∞ÄÏùÑÎåÄÎ°úÎ•º Í±∑Í≥†   Í≤®Ïö∏ÏùÄ Ï†êÏ†ê Í∞ÄÏùÑÎåÄÎ°úÎ•º Í±∑ÎÑ§.  ÎÇòÎäî ÎãπÏã† ÎßåÌÅº Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ¥Í≥† Ïã∂ÏùÄÎç∞  ÎÇòÎäî Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ¥Í≥† Ïã∂ÏùÄÎç∞  ÎãπÏã†ÎèÑ Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ∏ Îí§ Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ¥Î©¥  ÎÇòÎäî ÎãπÏã† ÎåÄÎ°ú Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ¥Í≥† Ïã∂ÏùÄÎç∞  \\n\"Ïò§ÎäòÏùÄ ÎÇ¥Í∞Ä Í∞ÄÏû• ÌñâÎ≥µÌïòÎã§Îäî Îã¨Ïù∏  Îã¨Î†• ÎßàÏßÄÎßâ Ïû• Îß® ÎßàÏßÄÎßâ Ï§Ñ ÎÅùÍπåÏßÄ ÌñâÎ≥µÌïúÎã§Îäî Îã¨Î†•  Íº≠ Î¥êÎèÑ ÏÇ¨ÎûëÌïúÎã§Îäî ÎãπÏã†Í≥º ÎÇòÎûÄÌûà Íº≠ Î∞îÎùºÎçò Îã¨  Íº≠ Î¥êÎèÑ ÏÇ¨ÎûëÌïúÎã§Îäî ÎãπÏã† Î∞îÎùºÎçò Îã¨  Íº≠ Î≥¥Í≥† ÏÇ¨ÎûëÌïúÎã§Í≥†  Íº≠ ÏûäÏßÄ ÏïäÍ≤†ÏäµÎãàÎã§.  \"\\n\"Îã¨ÎπõÏóê Îì§Îú¨ Ïó∞Ïù∏ÏùÑ Î∞îÎùºÎ≥¥Î©∞  Ïó∞Ïù∏ ÎòêÎäî Î∂ÄÎ∂Ä Îì± Îí§Î°ú Î∞îÏÅòÍ≤å Í±∏Ïùå ÏòÆÍ∏∞Îäî Ïù¥Îì§   Ï†ÄÎì§ ÏÇ¨Ïù¥Î°ú Îπà Í∞ÄÏßÄÎäî Îπà Í∞ÄÏßÄ ÎßêÎ¶¨ÎäêÎùº  Ïó∞Ïù∏Ï≤òÎüº Î∞úÍ±∏Ïùå ÎßûÏ∂∞ ÎÇòÎûÄÌûà  \"\\nÏÜåÎûÄÌïú Ïó¨Î¶ÑÎÇ†  ÎÑàÎäî ÎΩÄÏñÄ Íµ¨Î¶Ñ  Ïôú Ï†ÄÎûò Ï†ÄÎûò ÌîºÎÇòÎ∂ÄÎπÑÏ†ÅÏù∏Í∞Ä.  \\nÏó¨Î¶Ñ Ìïú Î≤à Î≥¥Î†§Í≥† ÎÇ¥ Í±∏ÏùåÏóê Ï†ú Í±∏ÏùåÏùÑ Ï°∞Í∏à Îä¶Ï∂îÎÑ§.  Ïä¨Î©∞'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "2HxSCBh-PYBz",
        "outputId": "92984b4e-97d5-4455-b403-bd621d8be2b3"
      },
      "source": [
        "sentence[len(input)+2:].strip('[\"\\n\"]')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ïó¨Ïú†Î°úÏõÄ  \"\\n\"ÎπóÏÜç Îã§ ÏßÄÎÇò Í∞ëÎãàÎã§.  ÎçîÎäî ÎπóÎ¨ºÏÜåÎ¶¨ Îì£ÏßÄ Îßê Í±∏.  Ïó¨ÏßÅÎèÑ Ï†ñÏùÄ Î™∏ ÎÖπÏùº Í≥≥ Î™ªÌïòÎÑ§.  \"\\n\"Ïó¨Î¶ÑÏùÄ Ï†êÏ†ê Ïó¨Î¶ÑÎåÄÎ°úÎ•º Í±∑Í≥† Í∞ÄÏùÑÏùÄ Í∞ÄÏùÑÎåÄÎ°úÎ•º Í±∑Í≥†   Í≤®Ïö∏ÏùÄ Ï†êÏ†ê Í∞ÄÏùÑÎåÄÎ°úÎ•º Í±∑ÎÑ§.  ÎÇòÎäî ÎãπÏã† ÎßåÌÅº Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ¥Í≥† Ïã∂ÏùÄÎç∞  ÎÇòÎäî Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ¥Í≥† Ïã∂ÏùÄÎç∞  ÎãπÏã†ÎèÑ Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ∏ Îí§ Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ¥Î©¥  ÎÇòÎäî ÎãπÏã† ÎåÄÎ°ú Í∞ÄÏùÑÏùÑ Î≥¥ÎÇ¥Í≥† Ïã∂ÏùÄÎç∞  \\n\"Ïò§ÎäòÏùÄ ÎÇ¥Í∞Ä Í∞ÄÏû• ÌñâÎ≥µÌïòÎã§Îäî Îã¨Ïù∏  Îã¨Î†• ÎßàÏßÄÎßâ Ïû• Îß® ÎßàÏßÄÎßâ Ï§Ñ ÎÅùÍπåÏßÄ ÌñâÎ≥µÌïúÎã§Îäî Îã¨Î†•  Íº≠ Î¥êÎèÑ ÏÇ¨ÎûëÌïúÎã§Îäî ÎãπÏã†Í≥º ÎÇòÎûÄÌûà Íº≠ Î∞îÎùºÎçò Îã¨  Íº≠ Î¥êÎèÑ ÏÇ¨ÎûëÌïúÎã§Îäî ÎãπÏã† Î∞îÎùºÎçò Îã¨  Íº≠ Î≥¥Í≥† ÏÇ¨ÎûëÌïúÎã§Í≥†  Íº≠ ÏûäÏßÄ ÏïäÍ≤†ÏäµÎãàÎã§.  \"\\n\"Îã¨ÎπõÏóê Îì§Îú¨ Ïó∞Ïù∏ÏùÑ Î∞îÎùºÎ≥¥Î©∞  Ïó∞Ïù∏ ÎòêÎäî Î∂ÄÎ∂Ä Îì± Îí§Î°ú Î∞îÏÅòÍ≤å Í±∏Ïùå ÏòÆÍ∏∞Îäî Ïù¥Îì§   Ï†ÄÎì§ ÏÇ¨Ïù¥Î°ú Îπà Í∞ÄÏßÄÎäî Îπà Í∞ÄÏßÄ ÎßêÎ¶¨ÎäêÎùº  Ïó∞Ïù∏Ï≤òÎüº Î∞úÍ±∏Ïùå ÎßûÏ∂∞ ÎÇòÎûÄÌûà  \"\\nÏÜåÎûÄÌïú Ïó¨Î¶ÑÎÇ†  ÎÑàÎäî ÎΩÄÏñÄ Íµ¨Î¶Ñ  Ïôú Ï†ÄÎûò Ï†ÄÎûò ÌîºÎÇòÎ∂ÄÎπÑÏ†ÅÏù∏Í∞Ä.  \\nÏó¨Î¶Ñ Ìïú Î≤à Î≥¥Î†§Í≥† ÎÇ¥ Í±∏ÏùåÏóê Ï†ú Í±∏ÏùåÏùÑ Ï°∞Í∏à Îä¶Ï∂îÎÑ§.  Ïä¨Î©∞'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Buwf30WePaPD",
        "outputId": "ce2ce6bb-e46e-4769-ba29-61aae4ac2b5a"
      },
      "source": [
        "# Ïã§Ìñâ\n",
        "# tok_k = 50, top_p = 0.95, epoch = 10\n",
        "input = 'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ'\n",
        "sequence = input\n",
        "max_length = 128\n",
        "# print('input :' + sequence)\n",
        "sentence = generate_text(sequence, max_length)\n",
        "sentence[len(input)+2:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/data/project03/gpt/results/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/data/project03/gpt/results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/data/project03/gpt/results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/data/project03/gpt/results/added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer_config.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Í¥úÌûà ÎßòÏùÑ Í∏âÌï¥ ÎÜìÍ≥†  Î∞îÎ°ú Ïû°ÏïÑ Ï±ÑÎ†§ÎÇò, Ìó§Îß§ÎäêÎùº  Îä¶ÏóàÎã§, ÏûêÏ±ÖÌïòÍ≥† Ïã∂Îã§.  \"\\n\"Îç•Îã§, Îç•Îã§Î©∞ Í∞ÄÎäî Í∏∏ÏòÜÏóê Ï†ÑÌôîÍ∞Ä ÎßéÎã§.  Í±∏Î†§Ïò§Îäî Ï†ÑÌôîÎøêÏù¥Îùº  Í±∏Î†§Ïò§Îäî Ï†ÑÌôîÏóê Ï£ÑÎã§ Ìï¥Î∞îÎùºÍ∏∞Î∂ÑÌïòÎãà  ÎçîÎäî Ï†ÑÌôîÌïòÏßÄ ÏïäÏïÑÎèÑ ÎêúÎã§.  \"\\n\"Îç•Îã§, Îç•Îã§Î©∞ Í∞ÄÎäî Í∏∏ÏòÜÏóê Ï£ºÏ∞®Ïû•  ÏÑ∏Ïö∞Îãà  Ìïú ÏÜêÎèÑ Î™ªÎêòÎäî Ï†ÄÎì§ÎÅºÎ¶¨ Ï∂îÏö∞ÎçîÎãà  Í±∞Îì† ÎßêÏóê  Í≤®Ïö∞ÎÇ¥ ÏÑúÏÑ±Ïù¥Îäî Î∞îÏßù ÎßàÎ•∏ Î∞îÎûåÏóêÎèÑ ÎÇ†ÏßÄ ÏïäÎäî Î∞îÎûå  Í∑∏ Î∞îÎûåÏóê ÎÇòÎäî ÎÖ∏ÎûÄ ÎØºÎì§Î†à '"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "C9OAOD2rTI_h",
        "outputId": "837c1f06-95c4-46c7-c988-b88831fdd499"
      },
      "source": [
        "sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ, Í¥úÌûà ÎßòÏùÑ Í∏âÌï¥ ÎÜìÍ≥†  Î∞îÎ°ú Ïû°ÏïÑ Ï±ÑÎ†§ÎÇò, Ìó§Îß§ÎäêÎùº  Îä¶ÏóàÎã§, ÏûêÏ±ÖÌïòÍ≥† Ïã∂Îã§.  \"\\n\"Îç•Îã§, Îç•Îã§Î©∞ Í∞ÄÎäî Í∏∏ÏòÜÏóê Ï†ÑÌôîÍ∞Ä ÎßéÎã§.  Í±∏Î†§Ïò§Îäî Ï†ÑÌôîÎøêÏù¥Îùº  Í±∏Î†§Ïò§Îäî Ï†ÑÌôîÏóê Ï£ÑÎã§ Ìï¥Î∞îÎùºÍ∏∞Î∂ÑÌïòÎãà  ÎçîÎäî Ï†ÑÌôîÌïòÏßÄ ÏïäÏïÑÎèÑ ÎêúÎã§.  \"\\n\"Îç•Îã§, Îç•Îã§Î©∞ Í∞ÄÎäî Í∏∏ÏòÜÏóê Ï£ºÏ∞®Ïû•  ÏÑ∏Ïö∞Îãà  Ìïú ÏÜêÎèÑ Î™ªÎêòÎäî Ï†ÄÎì§ÎÅºÎ¶¨ Ï∂îÏö∞ÎçîÎãà  Í±∞Îì† ÎßêÏóê  Í≤®Ïö∞ÎÇ¥ ÏÑúÏÑ±Ïù¥Îäî Î∞îÏßù ÎßàÎ•∏ Î∞îÎûåÏóêÎèÑ ÎÇ†ÏßÄ ÏïäÎäî Î∞îÎûå  Í∑∏ Î∞îÎûåÏóê ÎÇòÎäî ÎÖ∏ÎûÄ ÎØºÎì§Î†à '"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlF_fDFCTKbG",
        "outputId": "88c5613a-c96f-47ef-cc98-4ff565d6cb7f"
      },
      "source": [
        "import re\n",
        "sentence_re = re.sub('\"\\n', ' ', sentence[len(input)+2:])\n",
        "sentence_re\n",
        "tmp = sentence_re.split()\n",
        "tmp = ' '.join(tmp)\n",
        "tmp2 = tmp.split('.')\n",
        "sentence_new = []\n",
        "sentence_new.extend(tmp2)\n",
        "sentence_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Í¥úÌûà ÎßòÏùÑ Í∏âÌï¥ ÎÜìÍ≥† Î∞îÎ°ú Ïû°ÏïÑ Ï±ÑÎ†§ÎÇò, Ìó§Îß§ÎäêÎùº Îä¶ÏóàÎã§, ÏûêÏ±ÖÌïòÍ≥† Ïã∂Îã§',\n",
              " ' \"Îç•Îã§, Îç•Îã§Î©∞ Í∞ÄÎäî Í∏∏ÏòÜÏóê Ï†ÑÌôîÍ∞Ä ÎßéÎã§',\n",
              " ' Í±∏Î†§Ïò§Îäî Ï†ÑÌôîÎøêÏù¥Îùº Í±∏Î†§Ïò§Îäî Ï†ÑÌôîÏóê Ï£ÑÎã§ Ìï¥Î∞îÎùºÍ∏∞Î∂ÑÌïòÎãà ÎçîÎäî Ï†ÑÌôîÌïòÏßÄ ÏïäÏïÑÎèÑ ÎêúÎã§',\n",
              " ' \"Îç•Îã§, Îç•Îã§Î©∞ Í∞ÄÎäî Í∏∏ÏòÜÏóê Ï£ºÏ∞®Ïû• ÏÑ∏Ïö∞Îãà Ìïú ÏÜêÎèÑ Î™ªÎêòÎäî Ï†ÄÎì§ÎÅºÎ¶¨ Ï∂îÏö∞ÎçîÎãà Í±∞Îì† ÎßêÏóê Í≤®Ïö∞ÎÇ¥ ÏÑúÏÑ±Ïù¥Îäî Î∞îÏßù ÎßàÎ•∏ Î∞îÎûåÏóêÎèÑ ÎÇ†ÏßÄ ÏïäÎäî Î∞îÎûå Í∑∏ Î∞îÎûåÏóê ÎÇòÎäî ÎÖ∏ÎûÄ ÎØºÎì§Î†à']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mzkh1uKUa8G",
        "outputId": "5e0d9c4a-70b6-4178-c7ed-fcef7457abf7"
      },
      "source": [
        "# Ïã§Ìñâ\n",
        "# tok_k = 30, top_p = 0.95, repetition_penalty = 0.5, epoch = 10\n",
        "input = 'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ'\n",
        "sequence = input\n",
        "max_length = 128\n",
        "# print('input :' + sequence)\n",
        "sentence = generate_text(sequence, max_length)\n",
        "sentence_re = re.sub('\"\\n', ' ', sentence[len(input)+2:])\n",
        "sentence_re\n",
        "tmp = sentence_re.split()\n",
        "tmp = ' '.join(tmp)\n",
        "tmp2 = tmp.split('.')\n",
        "sentence_new = []\n",
        "sentence_new.extend(tmp2)\n",
        "sentence_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/data/project03/gpt/results/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/data/project03/gpt/results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/data/project03/gpt/results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/data/project03/gpt/results/added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer_config.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°úÏõÄ, Ïó¨Ïú†Î°ú']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LdBuae24Zh8K",
        "outputId": "d61e1ea7-568c-4d81-deb2-1645a4fb7a0b"
      },
      "source": [
        "# Ïã§Ìñâ\n",
        "# tok_k = 30, top_p = 0.95, repetition_penalty = 10, epoch = 5\n",
        "input = 'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ'\n",
        "sequence = input\n",
        "max_length = 128\n",
        "# print('input :' + sequence)\n",
        "sentence = generate_text(sequence, max_length)\n",
        "sentence_re = re.sub('\"\\n', ' ', sentence[len(input)+2:])\n",
        "sentence_re\n",
        "tmp = sentence_re.split()\n",
        "tmp = ' '.join(tmp)\n",
        "tmp2 = tmp.split('.')\n",
        "sentence_new = []\n",
        "sentence_new.extend(tmp2)\n",
        "sentence_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/data/project03/gpt/results/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/data/project03/gpt/results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/data/project03/gpt/results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/data/project03/gpt/results/added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer_config.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-30cff352d1fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print('input :' + sequence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msentence_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msentence_re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-b31c4094d00c>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(sequence, max_lenth)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mtok_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Í∞ÄÏû• ÎÜíÏùÄ ÌôïÎ•†ÏùÑ ÏßÄÎãå nÍ∞úÏùò Îã®Ïñ¥Ïàò Ï§ë Ï∂îÏ∂ú\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtop_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# ÎàÑÏ†ÅÌôïÎ•†Ïù¥ n%Ïù∏ Îã®Ïñ¥ÍπåÏßÄ Ìè¨Ìï®ÌïòÏó¨ Ï∂îÏ∂ú\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       \u001b[0mrepetition_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;31m# Îã®Ïñ¥ ÎπàÎèÑ Ìå®ÎÑêÌã∞\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m   )\n\u001b[1;32m     76\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beam_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiversity_penalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mremove_invalid_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_invalid_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m         )\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36m_get_logits_processor\u001b[0;34m(self, repetition_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, encoder_input_ids, bad_words_ids, min_length, max_length, eos_token_id, forced_bos_token_id, forced_eos_token_id, prefix_allowed_tokens_fn, num_beams, num_beam_groups, diversity_penalty, remove_invalid_values)\u001b[0m\n\u001b[1;32m    605\u001b[0m             )\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0mprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepetitionPenaltyLogitsProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mno_repeat_ngram_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_repeat_ngram_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0mprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNoRepeatNGramLogitsProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_repeat_ngram_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_logits_process.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, penalty)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`penalty` has to be a strictly positive float, but is {penalty}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `penalty` has to be a strictly positive float, but is 10"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UBYndmqdRtC",
        "outputId": "48a589ea-f620-4569-85bc-1ef048a97f66"
      },
      "source": [
        "# Ïã§Ìñâ\n",
        "# tok_k = 30, top_p = 0.95, epoch = 10\n",
        "input = 'ÎÇ®Ïûê Ïó¨Ïûê Ìï¥Î≥Ä Ïó¨Ïú†Î°úÏõÄ'\n",
        "sequence = input\n",
        "max_length = 128\n",
        "# print('input :' + sequence)\n",
        "sentence = generate_text(sequence, max_length)\n",
        "sentence_re = re.sub('\"\\n', ' ', sentence[len(input)+2:])\n",
        "sentence_re\n",
        "tmp = sentence_re.split()\n",
        "tmp = ' '.join(tmp)\n",
        "tmp2 = tmp.split('.')\n",
        "sentence_new = []\n",
        "sentence_new.extend(tmp2)\n",
        "sentence_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/data/project03/gpt/results/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 0,\n",
            "  \"created_date\": \"2021-04-28\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 51200\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/data/project03/gpt/results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/data/project03/gpt/results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Didn't find file /content/drive/MyDrive/data/project03/gpt/results/added_tokens.json. We won't load it.\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer_config.json\n",
            "loading file /content/drive/MyDrive/data/project03/gpt/results/tokenizer.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Í¥úÌûà ÎßòÏùÑ Í∏âÌï¥ ÎÜìÍ≥† Î∞îÎ°ú Ïû°ÏïÑ Ï±ÑÎ†§ÎÇò, Ìó§Îß§ÎäêÎùº Îä¶ÏóàÎã§, ÏûêÏ±ÖÌïòÍ≥† Ïã∂Îã§',\n",
              " ' \"Îç•Îã§, Îç•Îã§Î©∞ Í∞ÄÎäî Í∏∏ÏòÜÏóê Ï†ÑÌôîÍ∞Ä ÎßéÎã§',\n",
              " ' Í±∏Î†§Ïò§Îäî Ï†ÑÌôîÎøêÏù¥Îùº Í±∏Î†§Ïò§Îäî Ï†ÑÌôîÏóê Ï£ÑÎã§ Ìï¥Î∞îÎùºÍ∏∞Î∂ÑÌïòÎãà ÎçîÎäî Ï†ÑÌôîÌïòÏßÄ ÏïäÏïÑÎèÑ ÎêúÎã§',\n",
              " ' \"Îç•Îã§, Îç•Îã§Î©∞ Í∞ÄÎäî Í∏∏ÏòÜÏóê Ï£ºÏ∞®Ïû• ÏÑ∏Ïö∞Îãà Ìïú ÏÜêÎèÑ Î™ªÎêòÎäî Ï†ÄÎì§ÎÅºÎ¶¨ Ï∂îÏö∞ÎçîÎãà Í±∞Îì† ÎßêÏóê Í≤®Ïö∞ÎÇ¥ ÏÑúÏÑ±Ïù¥Îäî Î∞îÏßù ÎßàÎ•∏ Î∞îÎûåÏóêÎèÑ ÎÇ†ÏßÄ ÏïäÎäî Î∞îÎûå Í∑∏ Î∞îÎûåÏóê ÎÇòÎäî ÎÖ∏ÎûÄ ÎØºÎì§Î†à']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQm4ht_HdTUJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}